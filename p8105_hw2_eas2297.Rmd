---
title: "Homework 2"
author: "Eileen Shea"
date: "October 5, 2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

## Problem 1

First we need to read and clean the NYC transit data, while also retaining only the necessary variables and converting the _entry_ variable from character to logical:

```{r}
subway_data = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

The dataset we have right now is a subset of NYC Transit data that relates information about entrances and exits for each subway station in NYC. Variables that have been kept as part of our dataset are: line, station_name, station_latitude, station_longitude, route1-11, entry, vending, entrance_type, and ada. These data encompass numerous data types, including character variables (e.g. line, station_name), double variables (e.g. station_latitude, station_longitude), integer variables (e.g. route8, route11), and logical variables (e.g. ada, entry). So far, the data cleaning steps have involved turning all of the variable names into lower snake case, getting rid of extraneous variables, and converting between character and logical variable for _entry_. The dataset consits of 1868 rows and 19 columns. Right now, the dataset is not particularly tidy, especially due to the fact that some columns are values instead of variable names (i.e. route1-11 columns). 

First, we are curious about how many distinct stations there are:

```{r}
distinct_sub = subway_data %>% 
  distinct(line, station_name, .keep_all = TRUE)
```

From the above code chunk, we learn that there are **465** distinct subway stations.

Next, we are curious about how many stations are ADA compliant:

```{r}
sum(distinct_sub$ada)
```

It turns out that there are only **84** ADA compliant subway stations out of that bunch.

We are then curious about what proportion of station entrances / exits without vending allow entrance:

```{r}
no_vending = subway_data %>% 
  filter(vending == "NO")

sum(no_vending$entry)/length(no_vending$entry)
```

From this code chunk we learn that the proportion of station entrances / exits without vending that allow entrance is **0.377**.

Now it is important to reformat the dataset so that route number and route name are distinct variables:

```{r}
subway_tidy_data = gather(subway_data, key = rt_number, value = route_name, route1:route11) %>% 
  separate(rt_number, into = c("remove", "route_number"), sep = 5) %>% 
  select(everything(), -remove)
```

We also are interested in identifying how many distinct stations serve the A train:

```{r}
A_train = subway_tidy_data %>% 
  distinct(line, station_name, .keep_all = TRUE) %>% 
  filter(route_name == "A")

nrow(A_train)
```

The A train according to this dataset serves **60** distinct stations.

Of the stations that serve the A train, we are interested in which are ADA compliant:

```{r}
sum(A_train$ada)
```

Out of 60 A train stations, **17** are ADA compliant.


## Problem 2

First we need to read and clean the Excel file by specifying the Mr. Trash Wheel sheet and omitting the notes columns, using reasonable variable names, omitting rows that do not include dumpster-specific data, rounding the number of sports balls to the nearest integer, and converting this result to an integer variable:

```{r}
library(readxl)
mr_trash_wheel = 
  read_xlsx("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N338") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_ball_count = as.integer(round(sports_balls))) %>% 
  select(everything(), -sports_balls)
```

Next we will read and clean the precipitation data for 2016 and 2017. Steps include omitting rows without precipitation data (for 2016 and 2017 all rows have precipitation data) and adding a variable year:

```{r}
precip_2016 = read_xlsx("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2016 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2016)

precip_2017 = read_xlsx("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = "2017 Precipitation", range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = 2017)
```

We must then combine the datasets and convert month to a character variable:

```{r}
precipm_2016 = precip_2016 %>% 
  mutate(month = month.name)
                
precipm_2017 = precip_2017 %>% 
  mutate(month = month.name)

harbor_data_2016 = inner_join(mr_trash_wheel, precipm_2016)

harbor_data_2017 = inner_join(mr_trash_wheel, precipm_2017)

rename(harbor_data_2016, total_precip = total)
rename(harbor_data_2017, total_precip = total)
```

We have two datasets right now; one is a combination of Mr. Trash Wheel data and 2016 precipitation data (harbor_data_2016), while the other is a combination of Mr. Trash Wheel data and 2017 precipitation data (harbor_data_2017). Both are from the HealthyHarbor data collection's most recent update on July 28, 2018. The first dataset, harbor_data_2016, has `r nrow(harbor_data_2016)` observations while the second dataset, harbor_data_2017, has `r nrow(harbor_data_2017)` observations. Key variables in each dataset include the dumpster number (*dumpster*), the month and year this dumpster was collected (*month* and *year*), its weight in tons (*weight_tons*), its volume in cubic yards (*volume_cubic_yards*), and the total precipitation in inches (*total_precip*) for the corresponding month and year. The total precipitation amount for 2017 was `r sum(precipm_2017$total)` inches. The median number of sports balls in a dumpster in 2016 was `r median(harbor_data_2016$sports_ball_count)`.

## Problem 3

First we need to load the data from the p8105.datasets package:

```{r}
library(p8105.datasets)
data(brfss_smart2010)
```

Then we need to do the following manipulations: For this question: 1) format the data to use appropriate variable names, 2) focus on the “Overall Health” topic, 3) exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation, 4) structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data_value in the original dataset), 5) create a new variable showing the proportion of responses that were “Excellent” or “Very Good”.

```{r}
brfss_clean = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -(confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(excell_vgood = (excellent + very_good)/100)
```

### Now we are interested in the following questions/actions:

How many unique locations are included in the dataset? Is every state represented? What state is observed the most?

```{r}
brfss_clean %>% 
  distinct(locationdesc, .keep_all = TRUE) 

brfss_clean %>% 
  distinct(locationdesc, .keep_all = TRUE) %>% 
  distinct(locationabbr, .keep_all = TRUE)

brfss_clean %>% 
  distinct(locationdesc, .keep_all = TRUE) %>% 
  group_by(locationabbr) %>% 
  count(locationabbr)
```

From this code chunk we learn that there are 404 unique locations in the dataset. All 50 states are represented in the data, in addition to the District of Columbia. Florida is observed the most at 44 unique locations. 


In 2002, what is the median of the “Excellent” response value?


Make a histogram of “Excellent” response values in the year 2002.

```{r}
brfss_clean %>% 
  filter(year == 2002) %>%
  ggplot(aes(x = excellent)) + geom_histogram()
```

Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r}
brfss_clean %>% 
  filter(locationdesc == "NY - New York County" | locationdesc == "NY - Queens County") %>%
  ggplot(aes(x = year, y = excellent)) + geom_point(aes(color = locationdesc))
```




